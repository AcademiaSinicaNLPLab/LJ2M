
import os
import sys

import numpy as np
import argparse
import logging
import time

from common import utils
from common import filename
from common import output
from features.preprocessing import FeatureList

from sklearn.decomposition import TruncatedSVD


def get_arguments(argv):

    parser = argparse.ArgumentParser(description='reduce feature dimension')
    # parser.add_argument('feature_list_file', metavar='FEATURE_LIST_FILE', 
    #                     help='This program will fuse the features listed in this file and feed all of them to the classifier. The file format is in JSON. See "feautre_list_ex.json" for example')
    
    parser.add_argument('input_folder', metavar='INPUT_FOLDER', 
                        help='input folder that contains features')
    
    parser.add_argument('-o', '--output_folder', metavar='OUTPUT_FOLDER', default=output.get_folder_name_with_time('reduced'), 
                        help='output folder, if not specified, create it with name equal to system time')
    parser.add_argument('-e', '--emotion_ids', metavar='EMOTION_IDS', type=utils.parse_range, default=[0], 
                        help='a list that contains emotion ids ranged from 0-39 (DEFAULT: 0). This can be a range expression, e.g., 3-6,7,8,10-15')
    parser.add_argument('-i', '--index_file', metavar='INDEX_FILE', default=None, 
                        help='index file generated by batchGenRandomIndex.py')
    parser.add_argument('-n', '--target_n_component', metavar='TARGET_N_COMPONENT', type=int, default=300, 
                        help='reduced number of component in the end (DEFAULT: 300)')

    parser.add_argument('-v', '--verbose', action='store_true', default=False, 
                        help='show messages')
    parser.add_argument('-d', '--debug', action='store_true', default=False, 
                        help='show debug messages')

    args = parser.parse_args(argv)
    return args

    
if __name__ == '__main__':
    
    args = get_arguments(sys.argv[1:])

    if args.debug:
        loglevel = logging.DEBUG
    elif args.verbose:
        loglevel = logging.INFO
    else:
        loglevel = logging.ERROR
    logging.basicConfig(format='[%(levelname)s][%(name)s] %(message)s', level=loglevel) 
    logger = logging.getLogger(__name__)

    # pre-checking
    if not os.path.exists(args.output_folder):
        logger.info('create output folder %s' % (args.output_folder))
        os.makedirs(args.output_folder)


    all_idxs = utils.load_pkl_file(args.index_file) if args.index_file is not None else None
    emotions = filename.emotions['LJ40K']

    for emotion_id in args.emotion_ids:

        emotion_name = emotions[emotion_id]

        fname = filename.get_filename_by_emotion(emotion_name, args.input_folder)
        fpath = os.path.join(args.input_folder, fname)
        logger.info("load features from %s", fpath)
        Xy = utils.load_pkl_file(fpath)

        idxs = all_idxs['train'][emotion_name][emotion_name] if all_idxs is not None else range(len(Xy))

        X = np.zeros((len(idxs), Xy[0]['X'].shape[1]), dtype="float32")
        logger.info('X.shape = (%u, %u)' % (X.shape[0], X.shape[1]))

        for i in idxs:    
            # make sure only one feature vector in each doc
            assert Xy[i]['X'].shape[0] == 1         
            X[i] = Xy[i]['X']

        tsvd = TruncatedSVD(n_components=args.target_n_component)
        logger.info('start fitting for "%s"' % (emotion_name))

        start_time = time.time()
        X_new = tsvd.fit_transform(X)
        end_time = time.time()
        logger.info('fit time = %f' % (end_time-start_time))

        fname = os.path.basename(fpath)
        fpath = os.path.join(args.output_folder, fname)
        logger.info('ouputing %s' % (fpath))
        utils.save_pkl_file(X_new, fpath)

        fname = '%s_tsvd.pkl' % (emotion_name)
        fpath = os.path.join(args.output_folder, fname)
        logger.info('ouputing %s' % (fpath))
        utils.save_pkl_file(tsvd, fpath)
